# WF-RULES-REVIEW ‚Äî Auditor√≠a de implementaci√≥n de Rules (Windsurf) + Skills (Repo ‚Üí Coverage ‚Üí Gaps)

> **Fuente de verdad de rules (Windsurf):** `.windsurf/rules/*`  
> **Objetivo:** auditar un repositorio (folder) contra ese set de **rules** y generar **1 archivo por rule** en `docs/rules-review/` con evidencia, score y plan de mejora, **indicando qu√© Skill debe ejecutar cada tarea**.

---

## 0) Skills disponibles (referencia r√°pida)

Este workflow **solo usa** skills disponibles en `skills.zip`:

| Uso en el workflow                                                                      | Skill (name)                              | Skill ID                 |
| --------------------------------------------------------------------------------------- | ----------------------------------------- | ------------------------ |
| Preparaci√≥n, ejecuci√≥n local, CI/CD, observabilidad m√≠nima del proceso                  | `plataforma-build-deploy-operate-observe` | `SK-PLAT-OPS-001`        |
| Normalizaci√≥n/cat√°logo de rules y ‚Äúcalidad del inventario‚Äù (metadata, trazabilidad)     | `gestion-datos-calidad`                   | `SK-DATA-OPS-001`        |
| Mapeo arquitectura/gobernanza (taxonom√≠a por dominios, patrones, ADR/API governance)    | `gobierno-de-arquitectura-diseno`         | `SK-ARCH-GOV-001`        |
| Inspecci√≥n backend real (controllers/handlers/repos/events) y evaluaci√≥n CQRS/Hexagonal | `backend`                                 | `SK-BE-API-001`          |
| Evaluaci√≥n NFRs (concurrencia, idempotencia, resiliencia, consistencia)                 | `arquitectura-escalabilidad-resiliencia`  | `SK-SCALE-RES-001`       |
| Evaluaci√≥n de pruebas, BDD Given-When-Then, gates de calidad                            | `qa-calidad`                              | `SK-QA-001`              |
| Hallazgos de seguridad, privacidad y cumplimiento (baseline)                            | `seguridad-privacidad-compliance`         | `SK-SEC-COMP-001`        |
| Hardening/controles extra (R2+/R3) cuando las rules lo exijan                           | `seguridad-avanzada`                      | `SK-SEC-ADV-001`         |
| Consolidaci√≥n de resultados en formato ‚Äúreporte‚Äù (tabla, KPIs de coverage)              | `data-reporting`                          | `SK-DATA-001`            |
| Documentaci√≥n operable + criterios de salida + debt/plan de trabajo                     | `gestion-ingenieria-delivery`             | `SK-ENG-DELIVERY-001`    |
| Preparaci√≥n para auditor√≠as/certificaciones si las rules lo piden                       | `cumplimiento-certificaciones`            | `SK-COMPLIANCE-CERT-001` |

> **Nota:** si tu set de rules incluye copy/UX/legal disclaimers, puedes sumar `legal-product` (`SK-LEGAL-PRODUCT-001`) y/o `ux-ui` (`SK-UXUI-001`) **solo** para rules de esa naturaleza.

---

## 1) Outputs (artefactos)

```
docs/
  rules-review/
    README.md                       # √≠ndice + tabla de cobertura
    _inventory/
      folder-map.md                 # √°rbol + estad√≠sticas + hallazgos
      file-stats.json               # metadata agregada
    _catalog/
      rules.normalized.json         # rules normalizadas desde .windsurf/rules/*
      rules.index.md                # lista por dominio/m√≥dulo
    _evidence/
      <RULE_ID>.json                # evidencias (paths, s√≠mbolos, tests, eventos)
    RULE-<DOMAIN>-<RULE_ID>.md      # 1 archivo por rule con gaps + plan
```

---

## 2) Rubrica de nivel de implementaci√≥n (Score 0‚Äì5)

- **0 ‚Äî No evidencias:** no hay handlers, endpoints, casos de uso, ni tests.
- **1 ‚Äî Esqueleto:** DTOs/contratos o stubs, pero sin l√≥gica completa.
- **2 ‚Äî Parcial:** existe l√≥gica, pero faltan validaciones/edge cases/errores.
- **3 ‚Äî Funcional:** cumple flujo principal; faltan NFRs (idempotencia, observabilidad, resiliencia) o escenarios alternos.
- **4 ‚Äî Completo con pruebas:** BDD (Given-When-Then) + unit/integration + errores consistentes.
- **5 ‚Äî Production-grade:** 4 + eventos/AsyncAPI + trazas (OpenTelemetry) + logging (Winston) + m√©tricas/alertas + documentaci√≥n.

**Gates recomendados**

- Implementaci√≥n sin tests ‚áí m√°ximo **Score 3**.
- EDA sin idempotencia/dedupe (cuando aplica) ‚áí m√°ximo **Score 3**.
- `Score <= 2` ‚áí marcar como **bloqueante** si es core del MVP.

---

## 3) Flujo general (Mermaid)

```mermaid
flowchart TD
  A[Leer .windsurf/rules/*] --> B[Inventory del repo]
  B --> C[Normalizar rules -> rules.normalized.json]
  C --> D[Rule->Code Mapping (controllers/handlers/repos/events/tests)]
  D --> E[Scoring 0-5 + gaps]
  E --> F[Generar RULE-<DOMAIN>-<RULE_ID>.md]
  F --> G[Generar README + tabla de cobertura]
```

---

# 4) Workflow paso a paso (con Skill por tarea)

## Fase 0 ‚Äî Preparaci√≥n (carpetas + verificaci√≥n de rules)

### Tareas

1. Crear carpetas de salida.  
   **Skill ejecutor:** `plataforma-build-deploy-operate-observe` (`SK-PLAT-OPS-001`)

```bash
mkdir -p docs/rules-review/{_inventory,_catalog,_evidence}
```

2. Verificar que existan rules.  
   **Skill ejecutor:** `plataforma-build-deploy-operate-observe` (`SK-PLAT-OPS-001`)

```bash
ls -la .windsurf/rules
```

---

## Fase 1 ‚Äî Analizar folder (inventario + organizaci√≥n)

### Tareas

1. Generar √°rbol + estad√≠sticas del repo (extensiones, tama√±os, hotspots).  
   **Skill ejecutor:** `plataforma-build-deploy-operate-observe` (`SK-PLAT-OPS-001`)  
   **Skill apoyo:** `gestion-datos-calidad` (`SK-DATA-OPS-001`) para clasificaci√≥n y consistencia del inventario.

2. Identificar estructura Nx y mapa de dominios (apps/libs por m√≥dulo).  
   **Skill ejecutor:** `gobierno-de-arquitectura-diseno` (`SK-ARCH-GOV-001`)  
   **Skill apoyo:** `backend` (`SK-BE-API-001`) para reconocer patrones CQRS/Hexagonal reales.

### Artefactos

- `docs/rules-review/_inventory/folder-map.md`  
  **Skill ejecutor:** `gestion-ingenieria-delivery` (`SK-ENG-DELIVERY-001`) (documentaci√≥n operable)
- `docs/rules-review/_inventory/file-stats.json`  
  **Skill ejecutor:** `gestion-datos-calidad` (`SK-DATA-OPS-001`)

---

## Fase 2 ‚Äî Catalogar y normalizar rules (desde `.windsurf/rules/*`)

### Tareas

1. Leer/parsear rules (MD/JSON/YAML/TXT) desde `.windsurf/rules/*`.  
   **Skill ejecutor:** `gestion-datos-calidad` (`SK-DATA-OPS-001`)

2. Normalizar al modelo interno (id, domain, title, ACs, keywords, source_path).  
   **Skill ejecutor:** `gestion-datos-calidad` (`SK-DATA-OPS-001`)

3. Inferir/validar `domain` (auth/resources/availability/stockpile/reports/other) y mantener taxonom√≠a consistente.  
   **Skill ejecutor:** `gobierno-de-arquitectura-diseno` (`SK-ARCH-GOV-001`)

### Artefactos

- `docs/rules-review/_catalog/rules.normalized.json`  
  **Skill ejecutor:** `gestion-datos-calidad` (`SK-DATA-OPS-001`)
- `docs/rules-review/_catalog/rules.index.md`  
  **Skill ejecutor:** `gestion-ingenieria-delivery` (`SK-ENG-DELIVERY-001`)

---

## Fase 3 ‚Äî Rule vs Code (mapeo de evidencia)

### Tareas

1. Buscar evidencia por rule:
   - match por ID (si existe), keywords, rutas de dominio
   - patrones CQRS/Hexagonal/EDA
   - tests (`*.spec.ts`, `*.e2e-spec.ts`)  
     **Skill ejecutor:** `backend` (`SK-BE-API-001`)

2. Validar coherencia arquitect√≥nica de la evidencia (ports/adapters, commands/queries, events).  
   **Skill ejecutor:** `gobierno-de-arquitectura-diseno` (`SK-ARCH-GOV-001`)

3. Cuando aplique, detectar NFRs en evidencia (idempotencia, retries, DLQ, consistencia).  
   **Skill ejecutor:** `arquitectura-escalabilidad-resiliencia` (`SK-SCALE-RES-001`)

### Artefacto por rule

- `docs/rules-review/_evidence/<RULE_ID>.json`  
  **Skill ejecutor:** `backend` (`SK-BE-API-001`)

> Regla cr√≠tica: **no inventar paths** ‚Äî todo path debe existir.

---

## Fase 4 ‚Äî Scoring + Gap Analysis (por rule)

### Tareas (descomposici√≥n recomendada)

1. Gap funcional vs criterios de aceptaci√≥n (AC coverage).  
   **Skill ejecutor:** `backend` (`SK-BE-API-001`)

2. Gap de pruebas (BDD Given-When-Then, unit/integration/e2e/contract).  
   **Skill ejecutor:** `qa-calidad` (`SK-QA-001`)

3. Gap arquitect√≥nico (Hexagonal/CQRS/EDA, contract/versioning, eventos).  
   **Skill ejecutor:** `gobierno-de-arquitectura-diseno` (`SK-ARCH-GOV-001`)

4. Gap de resiliencia/concurrencia/consistencia/idempotencia.  
   **Skill ejecutor:** `arquitectura-escalabilidad-resiliencia` (`SK-SCALE-RES-001`)

5. Gap de observabilidad m√≠nima (logs estructurados, trazas, m√©tricas).  
   **Skill ejecutor:** `plataforma-build-deploy-operate-observe` (`SK-PLAT-OPS-001`)

6. Gap de seguridad/privacidad/compliance (si la rule lo toca).  
   **Skill ejecutor:** `seguridad-privacidad-compliance` (`SK-SEC-COMP-001`)  
   **Escalamiento (R2+/R3):** `seguridad-avanzada` (`SK-SEC-ADV-001`)  
   **Auditor√≠a/certs:** `cumplimiento-certificaciones` (`SK-COMPLIANCE-CERT-001`)

### Resultado

- `score 0..5` + lista priorizada de gaps (bloqueantes ‚Üí importantes ‚Üí nice-to-have)

---

## Fase 5 ‚Äî Generar 1 archivo por rule (requisito final)

Crear: `docs/rules-review/RULE-<DOMAIN>-<RULE_ID>.md`

### Tareas

1. Redactar el documento por rule con:
   - resumen, evidencia, gaps, plan por capas, tests BDD, DoD  
     **Skill ejecutor:** `gestion-ingenieria-delivery` (`SK-ENG-DELIVERY-001`)  
     **Skill apoyo (tests):** `qa-calidad` (`SK-QA-001`)

### Plantilla recomendada (obligatoria)

```md
# <RULE_ID> ‚Äî <TITLE>

## 1) Resumen

- Dominio: <domain>
- Score (0‚Äì5): <score>
- Estado: ‚úÖ Completa | üü° Parcial | üî¥ No implementada

## 2) Evidencia encontrada (paths)

- Controllers:
- Handlers / Use cases:
- Domain:
- Persistence:
- Events:
- Tests:

## 3) Qu√© falta para cumplir al 100% (Gaps)

### Funcional (ACs pendientes)

- [ ] AC-1 ‚Ä¶
- [ ] AC-2 ‚Ä¶

### Reglas/Edge cases

- [ ] Conflictos / concurrencia / l√≠mites ‚Ä¶
- [ ] Validaciones ‚Ä¶

### Arquitectura (Hexagonal/CQRS/EDA)

- [ ] Falta CommandHandler/QueryHandler ‚Ä¶
- [ ] Falta Port + Adapter ‚Ä¶
- [ ] Falta evento(s) ‚Ä¶

### Observabilidad / Operaci√≥n

- [ ] Winston logs estructurados (campos m√≠nimos: traceId, ruleId, userId‚Ä¶)
- [ ] OpenTelemetry spans relevantes
- [ ] Manejo de errores con c√≥digos consistentes

## 4) Plan de correcci√≥n (acciones concretas)

> Ordenadas por capas

### Domain

1. ‚Ä¶
2. ‚Ä¶

### Application (CQRS)

1. Command/Query + Handler ‚Ä¶
2. ‚Ä¶

### Infrastructure

1. Repo adapter ‚Ä¶
2. ‚Ä¶

### Tests (BDD Jasmine)

- **Given** ‚Ä¶
- **When** ‚Ä¶
- **Then** ‚Ä¶
  Casos m√≠nimos:
- [ ] Happy path
- [ ] Alterno 1
- [ ] Alterno 2
- [ ] Seguridad/Permisos
- [ ] Concurrencia/duplicados (si aplica)

## 5) Definition of Done (DoD)

- [ ] Todos los ACs cubiertos
- [ ] Tests BDD pasan
- [ ] Eventos/documentaci√≥n actualizada (si aplica)
- [ ] Observabilidad m√≠nima aplicada
```

---

## Fase 6 ‚Äî README de cobertura (√≠ndice final)

Generar `docs/rules-review/README.md`

### Tareas

1. Consolidar tabla de coverage (Rule/Dominio/Score/Estado/Link).  
   **Skill ejecutor:** `data-reporting` (`SK-DATA-001`)

2. Agregar resumen por dominio + top gaps por severidad.  
   **Skill ejecutor:** `gestion-ingenieria-delivery` (`SK-ENG-DELIVERY-001`)

---

# 5) Prompt listo para ejecutar en Windsurf (con skills)

```text
Objetivo: Ejecuta WF-RULES-REVIEW (Windsurf rules in .windsurf/rules/*) usando Skills expl√≠citos.

Fase 0 (SK-PLAT-OPS-001):
1) Verifica .windsurf/rules/* y prepara docs/rules-review/*.

Fase 1 (SK-PLAT-OPS-001 + SK-DATA-OPS-001 + SK-ARCH-GOV-001):
2) Genera inventario del repo: folder-map.md + file-stats.json.
3) Identifica estructura Nx y mapa de dominios.

Fase 2 (SK-DATA-OPS-001 + SK-ARCH-GOV-001):
4) Parse y normaliza rules a rules.normalized.json + rules.index.md.

Fase 3 (SK-BE-API-001 + SK-ARCH-GOV-001 + SK-SCALE-RES-001):
5) Por cada rule: recolecta evidencia (controllers/handlers/domain/repos/events/tests) y escribe _evidence/<RULE_ID>.json.

Fase 4 (SK-QA-001 + SK-SEC-COMP-001 + SK-PLAT-OPS-001 + SK-SCALE-RES-001 + SK-ARCH-GOV-001 + SK-BE-API-001):
6) Asigna score 0..5 y gaps por categor√≠as (funcional, tests, arquitectura, resiliencia, observabilidad, seguridad/compliance).

Fase 5 (SK-ENG-DELIVERY-001 + SK-QA-001):
7) Genera docs/rules-review/RULE-<DOMAIN>-<RULE_ID>.md por cada rule con la plantilla.

Fase 6 (SK-DATA-001 + SK-ENG-DELIVERY-001):
8) Genera docs/rules-review/README.md con tabla de cobertura y resumen por dominio.

Reglas:
- No inventes evidencias: todo path debe existir.
- Si domain no es expl√≠cito: infiere y marca ‚ö†Ô∏è.
- Mant√©n consistencia de scoring con los gates.
```

---

## 6) Notas de consistencia

- **Dominio desconocido:** `other` + `‚ö†Ô∏è` y documentar por qu√© no fue inferible.
- **Priorizaci√≥n de gaps:** funcional/AC ‚Üí arquitectura ‚Üí tests ‚Üí NFRs (resiliencia/obs/sec).
- **Evitar alucinaci√≥n:** si no existe evidencia, declarar ‚ÄúNo encontrada‚Äù y score 0‚Äì1.
